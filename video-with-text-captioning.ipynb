{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iu9-m6vbg40"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.models.video as video\n",
        "\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from collections import Counter\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COYsuHW0bkYp",
        "outputId": "65482bc9-cdb0-4ccc-cb00-45048b560847"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-09-30 16:57:59.339366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting ru-core-news-lg==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_lg-3.6.0/ru_core_news_lg-3.6.0-py3-none-any.whl (513.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m513.4/513.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ru-core-news-lg==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: pymorphy3>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ru-core-news-lg==3.6.0) (1.2.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.6.0) (0.7.2)\n",
            "Requirement already satisfied: docopt-ng>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.10/dist-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.6.0) (2.4.417150.4580142)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->ru-core-news-lg==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_lg')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download ru_core_news_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKMmR19odV35",
        "outputId": "3c5c0470-fd2c-479b-8ecc-13598fab8d92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-8oWdKQdYGM"
      },
      "outputs": [],
      "source": [
        "!cp ./drive/MyDrive/rutube_hackathon_novosibirsk.zip ./rutube_hackathon_novosibirsk.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blAMJ4Q1dZj6"
      },
      "outputs": [],
      "source": [
        "!zip -FF ./rutube_hackathon_novosibirsk.zip --out ./pleasework.zip\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVw9Kd4KdZq2"
      },
      "outputs": [],
      "source": [
        "!unzip -qq ./pleasework.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0C_wyV_dfbR",
        "outputId": "38092b7f-2f47-402f-d5d4-67a803060926"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['сергей',\n",
              " 'чуприн',\n",
              " 'любит',\n",
              " 'hi',\n",
              " '!',\n",
              " 'он',\n",
              " '-',\n",
              " 'картофелелюб',\n",
              " '!',\n",
              " '!',\n",
              " '!']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spacy_ru = spacy.load(\"ru_core_news_lg\")\n",
        "\n",
        "text = \"Сергей Чуприн любит hi! ОН - КАРТОфЕЛЕЛЮБ!!!\"\n",
        "[token.text.lower() for token in spacy_ru.tokenizer(text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a22M-_7didl"
      },
      "outputs": [],
      "source": [
        "train_csv = pd.read_csv(\"./rutube_hackathon_novosibirsk/train/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyNu5RBsdigf"
      },
      "outputs": [],
      "source": [
        "train_csv[\"len\"] = train_csv[\"description\"].apply(lambda x: len(x.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KChIus41dijW",
        "outputId": "b9ce7534-18b9-4628-eeae-717aa41412fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "321"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_csv.len.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9P_NBQnfuQE",
        "outputId": "0fa06016-df58-43a2-eeb3-05d5a1d688b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUwPVjmGbl_7"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self,freq_threshold):\n",
        "        self.itos = {0:\"<PAD>\", 1:\"<SOS>\", 2:\"<EOS>\", 3:\"<UNK>\"}\n",
        "\n",
        "        self.stoi = {v:k for k,v in self.itos.items()}\n",
        "\n",
        "        self.freq_threshold = freq_threshold\n",
        "\n",
        "    def __len__(self): return len(self.itos)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenize(text):\n",
        "        return [token.text.lower() for token in spacy_ru.tokenizer(text)]\n",
        "\n",
        "    def build_vocab(self, sentence_list):\n",
        "        frequencies = Counter()\n",
        "        idx = 4\n",
        "\n",
        "        for sentence in tqdm(sentence_list):\n",
        "            for word in self.tokenize(sentence):\n",
        "                frequencies[word] += 1\n",
        "\n",
        "                if frequencies[word] == self.freq_threshold:\n",
        "                    self.stoi[word] = idx\n",
        "                    self.itos[idx] = word\n",
        "                    idx += 1\n",
        "\n",
        "    @staticmethod\n",
        "    def del_timestamps(texts):\n",
        "        output = \"\"\n",
        "        for text in texts.split(\"\\n\"):\n",
        "          output += \"\".join(text.split(\"]  \")[1:]) + \" \"\n",
        "        return \" \".join(text)\n",
        "\n",
        "    def build_vocab(self, sentence_list, texts_list):\n",
        "      frequencies = Counter()\n",
        "      idx = 4\n",
        "\n",
        "      for sentence in tqdm(sentence_list):\n",
        "          for word in self.tokenize(sentence):\n",
        "              frequencies[word] += 1\n",
        "\n",
        "              if frequencies[word] == self.freq_threshold:\n",
        "                  self.stoi[word] = idx\n",
        "                  self.itos[idx] = word\n",
        "                  idx += 1\n",
        "\n",
        "      for text in tqdm(texts_list):\n",
        "          text = self.del_timestamps(text)\n",
        "          for word in self.tokenize(text):\n",
        "              frequencies[word] += 1\n",
        "\n",
        "              if frequencies[word] == self.freq_threshold:\n",
        "                  self.stoi[word] = idx\n",
        "                  self.itos[idx] = word\n",
        "                  idx += 1\n",
        "\n",
        "    def numericalize(self,text):\n",
        "        tokenized_text = self.tokenize(text)\n",
        "        return [ self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"] for token in tokenized_text ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGBqmkkSd_OJ"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, root_dir, captions, captions_files, transform=None,freq_threshold=1, build=True):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.texts = []\n",
        "        self.captions = captions\n",
        "\n",
        "        for file in tqdm(captions_files):\n",
        "            with open(self.root_dir + \"/train_stt/\" + file) as cf:\n",
        "                self.texts.append(\" \".join(cf.readlines()))\n",
        "\n",
        "        self.vocab = Vocabulary(freq_threshold)\n",
        "        if build:\n",
        "            self.vocab.build_vocab(self.captions, self.texts)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.captions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        caption = self.captions[idx]\n",
        "        text = self.texts[idx]\n",
        "\n",
        "        caption_vec = []\n",
        "        text_vec = []\n",
        "        caption_vec += [self.vocab.stoi[\"<SOS>\"]]\n",
        "        caption_vec += self.vocab.numericalize(caption)\n",
        "        caption_vec += [self.vocab.stoi[\"<EOS>\"]]\n",
        "\n",
        "        text_vec += [self.vocab.stoi[\"<SOS>\"]]\n",
        "        text_vec += self.vocab.numericalize(text)\n",
        "        text_vec += [self.vocab.stoi[\"<EOS>\"]]\n",
        "\n",
        "        if len(caption_vec) < 300:\n",
        "            for i in range(300 - len(caption_vec)):\n",
        "                caption_vec.append(0)\n",
        "\n",
        "        if len(text_vec) < 300:\n",
        "            for i in range(300 - len(text_vec)):\n",
        "                text_vec.append(0)\n",
        "\n",
        "        return torch.tensor(text_vec[:300]), torch.tensor(caption_vec[:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxGS1a5AeJjs"
      },
      "outputs": [],
      "source": [
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, root_dir, captions, video_files, texts, transform=None,freq_threshold=1, build=True):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.imgs = video_files\n",
        "        self.captions = captions\n",
        "\n",
        "        text = []\n",
        "        for file in tqdm(text):\n",
        "            with open(self.root_dir + \"/train_stt/\" + file) as cf:\n",
        "                    text.append(\" \".join(cf.readlines()))\n",
        "\n",
        "        self.vocab = Vocabulary(freq_threshold)\n",
        "        if build:\n",
        "            self.vocab.build_vocab(self.captions, texts)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def _read_video(self, path, frames_num=25, window=30):\n",
        "        frames = []\n",
        "        cap = cv2.VideoCapture(self.root_dir + \"/train_video/\" + path)\n",
        "\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "        length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        N = length // (frames_num)\n",
        "\n",
        "        current_frame = 1\n",
        "        for i in range(length):\n",
        "            ret, frame = cap.read(current_frame)\n",
        "            if ret and i == current_frame and len(frames) < frames_num:\n",
        "                size = 226, 226\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frame = cv2.resize(frame, size)\n",
        "                frames.append(frame)\n",
        "                current_frame += N\n",
        "\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        return np.array(frames)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        caption = self.captions[idx]\n",
        "        img = self.imgs[idx]\n",
        "        img = np.rollaxis(self._read_video(self.imgs[idx]), 3, 0)\n",
        "        img = np.array(np.array(img) / 255, dtype=np.float32)\n",
        "\n",
        "\n",
        "        caption_vec = []\n",
        "        caption_vec += [self.vocab.stoi[\"<SOS>\"]]\n",
        "        caption_vec += self.vocab.numericalize(caption)\n",
        "        caption_vec += [self.vocab.stoi[\"<EOS>\"]]\n",
        "        if len(caption_vec) < 300:\n",
        "            for i in range(300 - len(caption_vec)):\n",
        "                caption_vec.append(0)\n",
        "\n",
        "        return torch.tensor(img), torch.tensor(caption_vec[:300])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao9G1eMfeaKb"
      },
      "outputs": [],
      "source": [
        "class TextEncoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size=300, emb_dim=300, hid_dim=300, n_layers=3, dropout=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiQngzhHeklm"
      },
      "outputs": [],
      "source": [
        "class TextAttention(nn.Module):\n",
        "    def __init__(self, encoder_dim,decoder_dim,attention_dim):\n",
        "        super(TextAttention, self).__init__()\n",
        "\n",
        "        self.attention_dim = attention_dim\n",
        "\n",
        "        self.W = nn.Linear(decoder_dim,attention_dim)\n",
        "        self.U = nn.Linear(encoder_dim,attention_dim)\n",
        "\n",
        "        self.A = nn.Linear(attention_dim,1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, features, hidden_state):\n",
        "        u_hs = self.U(features)\n",
        "        w_ah = self.W(hidden_state)\n",
        "\n",
        "        combined_states = torch.tanh(u_hs + w_ah.unsqueeze(1))\n",
        "\n",
        "        attention_scores = self.A(combined_states)\n",
        "        attention_scores = attention_scores.squeeze(2)\n",
        "\n",
        "\n",
        "        alpha = F.softmax(attention_scores,dim=1)\n",
        "\n",
        "        attention_weights = features * alpha.unsqueeze(2)\n",
        "        attention_weights = attention_weights.sum(dim=1)\n",
        "\n",
        "        return alpha,attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKtHARUVetiR"
      },
      "outputs": [],
      "source": [
        "class TextDecoderRNN(nn.Module):\n",
        "    def __init__(self,embed_size, vocab_size, attention_dim,encoder_dim,decoder_dim,drop_prob=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.attention_dim = attention_dim\n",
        "        self.decoder_dim = decoder_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
        "        self.attention = TextAttention(encoder_dim,decoder_dim,attention_dim)\n",
        "\n",
        "\n",
        "        self.init_h = nn.Linear(encoder_dim, decoder_dim)\n",
        "        self.init_c = nn.Linear(encoder_dim, decoder_dim)\n",
        "        self.lstm_cell = nn.LSTMCell(embed_size+encoder_dim,decoder_dim,bias=True)\n",
        "        self.f_beta = nn.Linear(decoder_dim, encoder_dim)\n",
        "\n",
        "\n",
        "        self.fcn = nn.Linear(decoder_dim,vocab_size)\n",
        "        self.drop = nn.Dropout(drop_prob)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, features, captions):\n",
        "        embeds = self.embedding(captions)\n",
        "\n",
        "        h, c = self.init_hidden_state(features)\n",
        "\n",
        "        seq_length = len(captions[0])-1\n",
        "        batch_size = captions.size(0)\n",
        "        num_features = features.size(1)\n",
        "\n",
        "        preds = torch.zeros(batch_size, seq_length, self.vocab_size).to(device)\n",
        "        alphas = torch.zeros(batch_size, seq_length,num_features).to(device)\n",
        "\n",
        "        for s in range(seq_length):\n",
        "            alpha,context = self.attention(features, h)\n",
        "            lstm_input = torch.cat((embeds[:, s], context), dim=1)\n",
        "            h, c = self.lstm_cell(lstm_input, (h, c))\n",
        "\n",
        "            output = self.fcn(self.drop(h))\n",
        "\n",
        "            preds[:,s] = output\n",
        "            alphas[:,s] = alpha\n",
        "\n",
        "\n",
        "        return preds, alphas\n",
        "\n",
        "    def generate_caption(self,features, max_len=300 ,vocab=None):\n",
        "\n",
        "        batch_size = features.size(0)\n",
        "        h, c = self.init_hidden_state(features)\n",
        "\n",
        "        alphas = []\n",
        "        word = torch.tensor(vocab.stoi['<SOS>']).view(1,-1).to(device)\n",
        "        embeds = self.embedding(word)\n",
        "\n",
        "\n",
        "        captions = []\n",
        "\n",
        "        for i in range(max_len):\n",
        "            alpha,context = self.attention(features, h)\n",
        "\n",
        "            alphas.append(alpha.cpu().detach().numpy())\n",
        "\n",
        "            lstm_input = torch.cat((embeds[:, 0], context), dim=1)\n",
        "            h, c = self.lstm_cell(lstm_input, (h, c))\n",
        "            output = self.fcn(self.drop(h))\n",
        "            output = output.view(batch_size,-1)\n",
        "\n",
        "\n",
        "            predicted_word_idx = output.argmax(dim=1)\n",
        "\n",
        "            captions.append(predicted_word_idx.item())\n",
        "\n",
        "            if vocab.itos[predicted_word_idx.item()] == \"<EOS>\":\n",
        "                break\n",
        "\n",
        "            embeds = self.embedding(predicted_word_idx.unsqueeze(0))\n",
        "\n",
        "        return [vocab.itos[idx] for idx in captions],alphas\n",
        "\n",
        "\n",
        "    def init_hidden_state(self, encoder_out):\n",
        "        mean_encoder_out = encoder_out.mean(dim=1)\n",
        "        h = self.init_h(mean_encoder_out)\n",
        "        c = self.init_c(mean_encoder_out)\n",
        "        return h, c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6K_zAbde0Z3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class TextEncoderDecoder(nn.Module):\n",
        "    def __init__(self,embed_size, vocab_size, attention_dim,encoder_dim,decoder_dim,drop_prob=0.3):\n",
        "        super().__init__()\n",
        "        self.encoder = TextEncoderRNN(\n",
        "            vocab_size = vocab_size\n",
        "            )\n",
        "        self.decoder = TextDecoderRNN(\n",
        "            embed_size=embed_size,\n",
        "            vocab_size = vocab_size,\n",
        "            attention_dim=attention_dim,\n",
        "            encoder_dim=encoder_dim,\n",
        "            decoder_dim=decoder_dim\n",
        "        )\n",
        "\n",
        "    def forward(self, images, captions):\n",
        "        features = self.encoder(images)\n",
        "        outputs = self.decoder(features, captions)\n",
        "        return outputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy8eu0fye9cb"
      },
      "outputs": [],
      "source": [
        "class VideoEncoderCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VideoEncoderCNN, self).__init__()\n",
        "        self.swin_t = video.swin3d_s(pretrained=True)\n",
        "        for param in self.swin_t.parameters():\n",
        "            param.requires_grad_(False)\n",
        "        modules = list(self.swin_t.children())[:-2]\n",
        "        self.swin_t = nn.Sequential(*modules)\n",
        "\n",
        "\n",
        "    def forward(self, images):\n",
        "        features = self.swin_t(images)\n",
        "        features = features.view(features.size(0), -1, features.size(-1))\n",
        "        return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_PY9sLpe9ij"
      },
      "outputs": [],
      "source": [
        "class VideoAttention(nn.Module):\n",
        "    def __init__(self, encoder_dim,decoder_dim,attention_dim):\n",
        "        super(VideoAttention, self).__init__()\n",
        "\n",
        "        self.attention_dim = attention_dim\n",
        "\n",
        "        self.W = nn.Linear(decoder_dim,attention_dim)\n",
        "        self.U = nn.Linear(encoder_dim,attention_dim)\n",
        "\n",
        "        self.A = nn.Linear(attention_dim,1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, features, hidden_state):\n",
        "        u_hs = self.U(features)\n",
        "        w_ah = self.W(hidden_state)\n",
        "\n",
        "        combined_states = torch.tanh(u_hs + w_ah.unsqueeze(1))\n",
        "\n",
        "        attention_scores = self.A(combined_states)\n",
        "        attention_scores = attention_scores.squeeze(2)\n",
        "\n",
        "\n",
        "        alpha = F.softmax(attention_scores,dim=1)\n",
        "\n",
        "        attention_weights = features * alpha.unsqueeze(2)\n",
        "        attention_weights = attention_weights.sum(dim=1)\n",
        "\n",
        "        return alpha,attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEOTEjw6fPKo"
      },
      "outputs": [],
      "source": [
        "\n",
        "class VideoDecoderRNN(nn.Module):\n",
        "    def __init__(self,embed_size, vocab_size, attention_dim,encoder_dim,decoder_dim,drop_prob=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.attention_dim = attention_dim\n",
        "        self.decoder_dim = decoder_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
        "        self.attention = VideoAttention(encoder_dim,decoder_dim,attention_dim)\n",
        "\n",
        "\n",
        "        self.init_h = nn.Linear(encoder_dim, decoder_dim)\n",
        "        self.init_c = nn.Linear(encoder_dim, decoder_dim)\n",
        "        self.lstm_cell = nn.LSTMCell(embed_size+encoder_dim,decoder_dim,bias=True)\n",
        "        self.f_beta = nn.Linear(decoder_dim, encoder_dim)\n",
        "\n",
        "\n",
        "        self.fcn = nn.Linear(decoder_dim,vocab_size)\n",
        "        self.drop = nn.Dropout(drop_prob)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, features, captions):\n",
        "        embeds = self.embedding(captions)\n",
        "\n",
        "        h, c = self.init_hidden_state(features)\n",
        "\n",
        "        seq_length = len(captions[0])-1\n",
        "        batch_size = captions.size(0)\n",
        "        num_features = features.size(1)\n",
        "\n",
        "        preds = torch.zeros(batch_size, seq_length, self.vocab_size).to(device)\n",
        "        alphas = torch.zeros(batch_size, seq_length,num_features).to(device)\n",
        "\n",
        "        for s in range(seq_length):\n",
        "            alpha,context = self.attention(features, h)\n",
        "            lstm_input = torch.cat((embeds[:, s], context), dim=1)\n",
        "            h, c = self.lstm_cell(lstm_input, (h, c))\n",
        "\n",
        "            output = self.fcn(self.drop(h))\n",
        "\n",
        "            preds[:,s] = output\n",
        "            alphas[:,s] = alpha\n",
        "\n",
        "\n",
        "        return preds, alphas\n",
        "\n",
        "    def generate_caption(self,features, max_len=300 ,vocab=None):\n",
        "\n",
        "        batch_size = features.size(0)\n",
        "        h, c = self.init_hidden_state(features)\n",
        "\n",
        "        alphas = []\n",
        "        word = torch.tensor(vocab.stoi['<SOS>']).view(1,-1).to(device)\n",
        "        embeds = self.embedding(word)\n",
        "\n",
        "\n",
        "        captions = []\n",
        "\n",
        "        for i in range(max_len):\n",
        "            alpha,context = self.attention(features, h)\n",
        "\n",
        "            alphas.append(alpha.cpu().detach().numpy())\n",
        "\n",
        "            lstm_input = torch.cat((embeds[:, 0], context), dim=1)\n",
        "            h, c = self.lstm_cell(lstm_input, (h, c))\n",
        "            output = self.fcn(self.drop(h))\n",
        "            output = output.view(batch_size,-1)\n",
        "\n",
        "\n",
        "            predicted_word_idx = output.argmax(dim=1)\n",
        "\n",
        "            captions.append(predicted_word_idx.item())\n",
        "\n",
        "            if vocab.itos[predicted_word_idx.item()] == \"<EOS>\":\n",
        "                break\n",
        "\n",
        "            embeds = self.embedding(predicted_word_idx.unsqueeze(0))\n",
        "\n",
        "        return [vocab.itos[idx] for idx in captions],alphas\n",
        "\n",
        "\n",
        "    def init_hidden_state(self, encoder_out):\n",
        "        mean_encoder_out = encoder_out.mean(dim=1)\n",
        "        h = self.init_h(mean_encoder_out)\n",
        "        c = self.init_c(mean_encoder_out)\n",
        "        return h, c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9nyGWAHfiiL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class VideoEncoderDecoder(nn.Module):\n",
        "    def __init__(self,embed_size, vocab_size, attention_dim,encoder_dim,decoder_dim,drop_prob=0.3):\n",
        "        super().__init__()\n",
        "        self.encoder = VideoEncoderCNN()\n",
        "        self.decoder = VideoDecoderRNN(\n",
        "            embed_size=embed_size,\n",
        "            vocab_size=vocab_size,\n",
        "            attention_dim=attention_dim,\n",
        "            encoder_dim=encoder_dim,\n",
        "            decoder_dim=decoder_dim\n",
        "        )\n",
        "\n",
        "    def forward(self, images, captions):\n",
        "        features = self.encoder(images)\n",
        "        outputs = self.decoder(features, captions)\n",
        "        return outputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENsumBkje9lp"
      },
      "outputs": [],
      "source": [
        "class ModelDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, root_dir, captions, video_files, text_files, vocab: Vocabulary,\n",
        "        video_model_state, text_model_state, batch_size, transform=None, freq_threshold=1\n",
        "        ):\n",
        "        self.transforms = T.Compose([\n",
        "            T.Resize(226),\n",
        "            T.RandomCrop(224),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
        "        ])\n",
        "\n",
        "\n",
        "        self.video_dataset =  VideoDataset(\n",
        "            root_dir=root_dir,\n",
        "            captions=captions,\n",
        "            video_files=video_files,\n",
        "            texts=text_files,\n",
        "            transform=transforms,\n",
        "            build=False\n",
        "        )\n",
        "        self.text_dataset = TextDataset(\n",
        "            root_dir=root_dir,\n",
        "            captions=captions,\n",
        "            captions_files=text_files,\n",
        "            transform=transforms,\n",
        "            build=False\n",
        "        )\n",
        "        self.vocab = vocab\n",
        "        self.video_dataset.vocab = self.vocab\n",
        "        self.text_dataset.vocab = self.vocab\n",
        "\n",
        "        self.text_model = TextEncoderDecoder(\n",
        "            embed_size=text_model_state[\"embed_size\"],\n",
        "            vocab_size = text_model_state['vocab_size'],\n",
        "            attention_dim=text_model_state['attention_dim'],\n",
        "            encoder_dim=text_model_state['encoder_dim'],\n",
        "            decoder_dim=text_model_state['decoder_dim']\n",
        "        ).to(device)\n",
        "        self.text_model.load_state_dict(text_model_state[\"state_dict\"])\n",
        "        self.text_model.requires_grad_ = False\n",
        "        self.text_model.eval()\n",
        "\n",
        "        self.video_model = VideoEncoderDecoder(\n",
        "            embed_size=video_model_state[\"embed_size\"],\n",
        "            vocab_size = video_model_state['vocab_size'],\n",
        "            attention_dim=video_model_state['attention_dim'],\n",
        "            encoder_dim=video_model_state['encoder_dim'],\n",
        "            decoder_dim=video_model_state['decoder_dim']\n",
        "        ).to(device)\n",
        "        self.video_model.load_state_dict(video_model_state[\"state_dict\"])\n",
        "        self.video_model.requires_grad_ = False\n",
        "        self.video_model.eval()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_dataset)\n",
        "\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        text, caption = self.text_dataset[idx]\n",
        "        video, caption = self.video_dataset[idx]\n",
        "        text = text.unsqueeze(0)\n",
        "        video = video.unsqueeze(0)\n",
        "        # print(text.shape, video.shape)\n",
        "        with torch.no_grad():\n",
        "            features = self.video_model.encoder(video[0:1].to(device))\n",
        "            caps, alphas = self.video_model.decoder.generate_caption(features, vocab=self.text_dataset.vocab)\n",
        "            video_caption = ' '.join(caps)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = self.text_model.encoder(text[0:1].to(device))\n",
        "            caps, alphas = self.text_model.decoder.generate_caption(features, vocab=self.text_dataset.vocab)\n",
        "            text_caption = ' '.join(caps)\n",
        "\n",
        "        video_vec = []\n",
        "        text_vec = []\n",
        "        caption_vec = []\n",
        "\n",
        "        video_vec += [self.vocab.stoi[\"<SOS>\"]]\n",
        "        video_vec += self.vocab.numericalize(video_caption)\n",
        "        video_vec += [self.vocab.stoi[\"<EOS>\"]]\n",
        "\n",
        "        text_vec += [self.vocab.stoi[\"<SOS>\"]]\n",
        "        text_vec += self.vocab.numericalize(text_caption)\n",
        "        text_vec += [self.vocab.stoi[\"<EOS>\"]]\n",
        "\n",
        "        if len(video_vec) < 300:\n",
        "            for i in range(300 - len(video_vec)):\n",
        "                video_vec.append(0)\n",
        "\n",
        "        if len(text_vec) < 300:\n",
        "            for i in range(300 - len(text_vec)):\n",
        "                text_vec.append(0)\n",
        "\n",
        "        return torch.cat([\n",
        "            torch.tensor(text_vec[:300]), torch.tensor(video_vec[:300])\n",
        "        ]), caption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183,
          "referenced_widgets": [
            "d47b553049dc4448996d083a05fad32e",
            "437ca6158fdf4165a42805c0c4cb4c23",
            "69101fa206c247f48df456eb1f3d0321",
            "4f4f801249b844eda135a284e62754c0",
            "666fbf0acf674c6299369e1069147fdc",
            "8287e3b2ecf6400b94d48b6b763aa0cc",
            "ddbb91e33394474985ea4934d09984a6",
            "b436a053ba284c4eb18cc7b1be97add4",
            "43e1613cbf814abb8be2c5c7dd6eaa6e",
            "034d13d057834caebe746182b388af2d",
            "6b849bafd89e4dfd8cb0375f63a8ea05",
            "34c1e90e080b4838af2e9ef3e13ee5a6",
            "0415fed68ecf49e8b6ef93a7d1abd885",
            "652c8a8cc9044bbfbd0250f8d4986bdc",
            "61d9fb8b3c3845358401afdb915a25b2",
            "d170d01fda2641dfafffb7f667e15e67",
            "fb1468fab3ec48ae972ee470f46602b4",
            "062159304d194e448aece861cb827671",
            "80599b92522f45da9c25e98aebeffd7d",
            "f03602def896441798d02d56ad43266b",
            "aca07b2a90ff46bb86e208f7ba6418c4",
            "0543e4c66952455391d1fbbe8ce3ab06"
          ]
        },
        "id": "BEXpNoyEe9oo",
        "outputId": "83f6ca89-bd57-4474-a8dc-cc305ff4e57b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d47b553049dc4448996d083a05fad32e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34c1e90e080b4838af2e9ef3e13ee5a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin3D_S_Weights.KINETICS400_V1`. You can also use `weights=Swin3D_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_location =  \"./rutube_hackathon_novosibirsk/train\"\n",
        "BATCH_SIZE = 50\n",
        "\n",
        "transforms = T.Compose([\n",
        "    T.Resize(226),\n",
        "    T.RandomCrop(224),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "\n",
        "dataset = ModelDataset(\n",
        "    root_dir=data_location,\n",
        "    captions=train_csv.description.tolist(),\n",
        "    video_files=train_csv.video_name.tolist(),\n",
        "    text_files=train_csv.stt_name.tolist(),\n",
        "    vocab=pickle.load(open(\"./vocab.pkl\", \"rb\")),\n",
        "    video_model_state=torch.load(\"./drive/MyDrive/video_model.pth\"),\n",
        "    text_model_state=torch.load(\"./drive/MyDrive/text_model.pth\"),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "\n",
        "data_loader = DataLoader(\n",
        "    dataset=dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "vocab_size = len(dataset.vocab)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7vePGXPvvbR"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size=300, emb_dim=300, hid_dim=300, n_layers=3, dropout=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obzNCbwiwLRq"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, encoder_dim,decoder_dim,attention_dim):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "        self.attention_dim = attention_dim\n",
        "\n",
        "        self.W = nn.Linear(decoder_dim,attention_dim)\n",
        "        self.U = nn.Linear(encoder_dim,attention_dim)\n",
        "\n",
        "        self.A = nn.Linear(attention_dim,1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, features, hidden_state):\n",
        "        u_hs = self.U(features)\n",
        "        w_ah = self.W(hidden_state)\n",
        "\n",
        "        combined_states = torch.tanh(u_hs + w_ah.unsqueeze(1))\n",
        "\n",
        "        attention_scores = self.A(combined_states)\n",
        "        attention_scores = attention_scores.squeeze(2)\n",
        "\n",
        "\n",
        "        alpha = F.softmax(attention_scores,dim=1)\n",
        "\n",
        "        attention_weights = features * alpha.unsqueeze(2)\n",
        "        attention_weights = attention_weights.sum(dim=1)\n",
        "\n",
        "        return alpha,attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLY_hJx2wRkq"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self,embed_size, vocab_size, attention_dim,encoder_dim,decoder_dim,drop_prob=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.attention_dim = attention_dim\n",
        "        self.decoder_dim = decoder_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
        "        self.attention = Attention(encoder_dim,decoder_dim,attention_dim)\n",
        "\n",
        "\n",
        "        self.init_h = nn.Linear(encoder_dim, decoder_dim)\n",
        "        self.init_c = nn.Linear(encoder_dim, decoder_dim)\n",
        "        self.lstm_cell = nn.LSTMCell(embed_size+encoder_dim,decoder_dim,bias=True)\n",
        "        self.f_beta = nn.Linear(decoder_dim, encoder_dim)\n",
        "\n",
        "\n",
        "        self.fcn = nn.Linear(decoder_dim,vocab_size)\n",
        "        self.drop = nn.Dropout(drop_prob)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, features, captions):\n",
        "        embeds = self.embedding(captions)\n",
        "\n",
        "        h, c = self.init_hidden_state(features)\n",
        "\n",
        "        seq_length = len(captions[0])-1\n",
        "        batch_size = captions.size(0)\n",
        "        num_features = features.size(1)\n",
        "\n",
        "        preds = torch.zeros(batch_size, seq_length, self.vocab_size).to(device)\n",
        "        alphas = torch.zeros(batch_size, seq_length,num_features).to(device)\n",
        "\n",
        "        for s in range(seq_length):\n",
        "            alpha,context = self.attention(features, h)\n",
        "            lstm_input = torch.cat((embeds[:, s], context), dim=1)\n",
        "            h, c = self.lstm_cell(lstm_input, (h, c))\n",
        "\n",
        "            output = self.fcn(self.drop(h))\n",
        "\n",
        "            preds[:,s] = output\n",
        "            alphas[:,s] = alpha\n",
        "\n",
        "\n",
        "        return preds, alphas\n",
        "\n",
        "    def generate_caption(self,features, max_len=300 ,vocab=None):\n",
        "\n",
        "        batch_size = features.size(0)\n",
        "        h, c = self.init_hidden_state(features)\n",
        "\n",
        "        alphas = []\n",
        "        word = torch.tensor(vocab.stoi['<SOS>']).view(1,-1).to(device)\n",
        "        embeds = self.embedding(word)\n",
        "\n",
        "\n",
        "        captions = []\n",
        "\n",
        "        for i in range(max_len):\n",
        "            alpha,context = self.attention(features, h)\n",
        "\n",
        "            alphas.append(alpha.cpu().detach().numpy())\n",
        "\n",
        "            lstm_input = torch.cat((embeds[:, 0], context), dim=1)\n",
        "            h, c = self.lstm_cell(lstm_input, (h, c))\n",
        "            output = self.fcn(self.drop(h))\n",
        "            output = output.view(batch_size,-1)\n",
        "\n",
        "\n",
        "            predicted_word_idx = output.argmax(dim=1)\n",
        "\n",
        "            captions.append(predicted_word_idx.item())\n",
        "\n",
        "            if vocab.itos[predicted_word_idx.item()] == \"<EOS>\":\n",
        "                break\n",
        "\n",
        "            embeds = self.embedding(predicted_word_idx.unsqueeze(0))\n",
        "\n",
        "        return [vocab.itos[idx] for idx in captions],alphas\n",
        "\n",
        "\n",
        "    def init_hidden_state(self, encoder_out):\n",
        "        mean_encoder_out = encoder_out.mean(dim=1)\n",
        "        h = self.init_h(mean_encoder_out)\n",
        "        c = self.init_c(mean_encoder_out)\n",
        "        return h, c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtfJG5S3wdXX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self,embed_size, vocab_size, attention_dim,encoder_dim,decoder_dim,drop_prob=0.3):\n",
        "        super().__init__()\n",
        "        self.encoder = EncoderRNN(\n",
        "            vocab_size = vocab_size\n",
        "            )\n",
        "        self.decoder = DecoderRNN(\n",
        "            embed_size=embed_size,\n",
        "            vocab_size = vocab_size,\n",
        "            attention_dim=attention_dim,\n",
        "            encoder_dim=encoder_dim,\n",
        "            decoder_dim=decoder_dim\n",
        "        )\n",
        "\n",
        "    def forward(self, images, captions):\n",
        "        features = self.encoder(images)\n",
        "        outputs = self.decoder(features, captions)\n",
        "        return outputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVlTgsRmwlNB"
      },
      "outputs": [],
      "source": [
        "embed_size=300\n",
        "vocab_size = len(dataset.vocab)\n",
        "attention_dim=256\n",
        "encoder_dim=300\n",
        "decoder_dim=512\n",
        "learning_rate = 4e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPXXQXSNwtbU"
      },
      "outputs": [],
      "source": [
        "#init model\n",
        "model = EncoderDecoder(\n",
        "    embed_size=embed_size,\n",
        "    vocab_size=vocab_size,\n",
        "    attention_dim=attention_dim,\n",
        "    encoder_dim=encoder_dim,\n",
        "    decoder_dim=decoder_dim\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=dataset.vocab.stoi[\"<PAD>\"])\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdtjqQPEwub5"
      },
      "outputs": [],
      "source": [
        "#helper function to save the model\n",
        "def save_model(model,num_epochs):\n",
        "    model_state = {\n",
        "        'num_epochs':num_epochs,\n",
        "        'embed_size':embed_size,\n",
        "        'vocab_size':len(dataset.vocab),\n",
        "        'attention_dim':attention_dim,\n",
        "        'encoder_dim':encoder_dim,\n",
        "        'decoder_dim':decoder_dim,\n",
        "        'state_dict':model.state_dict()\n",
        "    }\n",
        "\n",
        "    torch.save(model_state,'./drive/MyDrive/full_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a889mRsPwyIP",
        "outputId": "e8613675-3906-44af-bffd-52454efb2382"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.translate import meteor\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmPhrmzcwzwh"
      },
      "outputs": [],
      "source": [
        "def score(text, text_sum):\n",
        "    text = text.replace(\"<PAD>\", \"\")\n",
        "    if isinstance(text_sum, str):\n",
        "        return round(meteor([word_tokenize(text)],word_tokenize(text_sum)), 4)\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 97,
          "referenced_widgets": [
            "2f4e3a3d57d0421b96eff4a27fb2e822",
            "6db88d5fccd54570acfba5cd3fc489ce",
            "7f20d3a4e1b34d0c96f36a42125aba2a",
            "ca647d8fd81e49c8a16525ef7fc0ee0e",
            "ea06ea8e2c4d4e75b4c8fad5cd9a6130",
            "85bb0bdd1df14988b23592f2892a281a",
            "47c156e672474744b9e758736ab33b3a",
            "09fccfab2c384d4ab14369a5d5091c4e",
            "bbb1921f6b9343e3b43d55103a9e5c17",
            "9e15748d70f346dca29f5fc8b7693a58",
            "8057e16bdf9d4c64a10856edcb9d2837",
            "b15d8b41db684c5e8a467d2b4cb4fa85",
            "1582dbf73cbb49ce98c9d69e3c5cae97",
            "586b0293badc412e9b031918b90238c1",
            "6d7719c6ff7b4b11b386966a95f04135",
            "c5709476f9844483a5b92ca09b7ea30f",
            "d19b9c2edc154314bc5cff40a8c58349",
            "c68c59833bc744d493abceee8527662b",
            "e1c715a482f64dea9d9535d293bcdf43",
            "e9ef2855f5574d078f23391d9f36351a",
            "61d7a7d3c0fd4d74b9c121194024854e",
            "9af5e19b383e4d2d856450fe45595b02",
            "c62945a715974b449516434ca705cf50",
            "55cc851ad5b4487293fd95ef1090bfd2",
            "df8562d044eb499081ad642e999060ec"
          ]
        },
        "id": "qH42aq01w05Y",
        "outputId": "a0b88674-ea22-4747-e59c-455772f508bb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f4e3a3d57d0421b96eff4a27fb2e822",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b15d8b41db684c5e8a467d2b4cb4fa85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 8.901432037353516 score: 0.0068\n",
            "loss: 8.893943786621094 score: 0.0094\n",
            "loss: 8.875504493713379 score: 0.046\n",
            "loss: 8.854141235351562 score: 0.0402\n",
            "loss: 8.827407836914062 score: 0.1352\n",
            "loss: 8.782187461853027 score: 0.0628\n",
            "loss: 8.722457885742188 score: 0.0724\n",
            "loss: 8.648955345153809 score: 0.0\n",
            "loss: 8.485517501831055 score: 0.041\n",
            "loss: 8.282970428466797 score: 0.042\n",
            "Epoch loss: 8.72745\n",
            "Epoch: 2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c62945a715974b449516434ca705cf50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 8.075401306152344 score: 0.041\n",
            "loss: 7.861804962158203 score: 0.0325\n",
            "loss: 7.66754150390625 score: 0.028\n",
            "loss: 7.648908615112305 score: 0.0443\n",
            "loss: 7.377035617828369 score: 0.0296\n",
            "loss: 7.347804546356201 score: 0.0185\n",
            "loss: 7.27073335647583 score: 0.0191\n",
            "loss: 7.206053733825684 score: 0.0371\n",
            "loss: 7.223572731018066 score: 0.0274\n",
            "loss: 7.175075531005859 score: 0.02\n",
            "Epoch loss: 7.48539\n",
            "Epoch: 3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55cc851ad5b4487293fd95ef1090bfd2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 7.117039203643799 score: 0.0154\n",
            "loss: 6.984583377838135 score: 0.0179\n",
            "loss: 7.100799560546875 score: 0.1198\n",
            "loss: 6.887745380401611 score: 0.098\n",
            "loss: 7.0797624588012695 score: 0.0948\n",
            "loss: 7.117587089538574 score: 0.0484\n",
            "loss: 7.187944412231445 score: 0.132\n",
            "loss: 7.162382125854492 score: 0.0693\n",
            "loss: 7.169386386871338 score: 0.184\n",
            "loss: 6.922194004058838 score: 0.1211\n",
            "Epoch loss: 7.07294\n",
            "Epoch: 4\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df8562d044eb499081ad642e999060ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 6.942858695983887 score: 0.2231\n",
            "loss: 6.921104431152344 score: 0.0692\n",
            "loss: 6.883472442626953 score: 0.0359\n",
            "loss: 6.960726737976074 score: 0.0314\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 25\n",
        "print_every = 1\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "for epoch in tqdm(range(1, num_epochs + 1)):\n",
        "    losses = []\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "    try:\n",
        "        for idx, (image, captions) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "            # print(image.shape[2])\n",
        "            # if image.shape[2] < 50:\n",
        "            #     continue\n",
        "            image, captions = image.to(device),captions.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs,attentions = model(image, captions)\n",
        "\n",
        "            loss = criterion(outputs.view(-1, vocab_size), captions[:, 1:].reshape(-1))\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            if idx % print_every == 0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    dataiter = iter(data_loader)\n",
        "                    img,targ = next(dataiter)\n",
        "                    features = model.encoder(img[0:1].to(device))\n",
        "                    caps, alphas = model.decoder.generate_caption(features, vocab=dataset.vocab)\n",
        "                    caption = ' '.join(caps)\n",
        "                    target = \" \".join([dataset.vocab.itos[i] for i in targ[0:1][0][1:].tolist()])\n",
        "                    print(\"true:\", target)\n",
        "                    print(\"pred:\", caption)\n",
        "                    print(\"loss:\", loss.item(), \"score:\", score(target, caption))\n",
        "\n",
        "\n",
        "                model.train()\n",
        "    except Exception as ex:\n",
        "        print(\"Err:\", ex)\n",
        "        raise ex\n",
        "    if len(losses) != 0:\n",
        "        print(\"Epoch loss: {:.5f}\".format(sum(losses) / len(losses)))\n",
        "    else:\n",
        "        print(losses)\n",
        "    #save the latest model\n",
        "    save_model(model,epoch)\n",
        "    # clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b23ZysV3w3OW"
      },
      "outputs": [],
      "source": [
        "2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5OoGCWrvP8P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "034d13d057834caebe746182b388af2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0415fed68ecf49e8b6ef93a7d1abd885": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb1468fab3ec48ae972ee470f46602b4",
            "placeholder": "​",
            "style": "IPY_MODEL_062159304d194e448aece861cb827671",
            "value": "100%"
          }
        },
        "0543e4c66952455391d1fbbe8ce3ab06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "062159304d194e448aece861cb827671": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09fccfab2c384d4ab14369a5d5091c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1582dbf73cbb49ce98c9d69e3c5cae97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d19b9c2edc154314bc5cff40a8c58349",
            "placeholder": "​",
            "style": "IPY_MODEL_c68c59833bc744d493abceee8527662b",
            "value": "  0%"
          }
        },
        "2f4e3a3d57d0421b96eff4a27fb2e822": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6db88d5fccd54570acfba5cd3fc489ce",
              "IPY_MODEL_7f20d3a4e1b34d0c96f36a42125aba2a",
              "IPY_MODEL_ca647d8fd81e49c8a16525ef7fc0ee0e"
            ],
            "layout": "IPY_MODEL_ea06ea8e2c4d4e75b4c8fad5cd9a6130"
          }
        },
        "34c1e90e080b4838af2e9ef3e13ee5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0415fed68ecf49e8b6ef93a7d1abd885",
              "IPY_MODEL_652c8a8cc9044bbfbd0250f8d4986bdc",
              "IPY_MODEL_61d9fb8b3c3845358401afdb915a25b2"
            ],
            "layout": "IPY_MODEL_d170d01fda2641dfafffb7f667e15e67"
          }
        },
        "437ca6158fdf4165a42805c0c4cb4c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8287e3b2ecf6400b94d48b6b763aa0cc",
            "placeholder": "​",
            "style": "IPY_MODEL_ddbb91e33394474985ea4934d09984a6",
            "value": ""
          }
        },
        "43e1613cbf814abb8be2c5c7dd6eaa6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47c156e672474744b9e758736ab33b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f4f801249b844eda135a284e62754c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_034d13d057834caebe746182b388af2d",
            "placeholder": "​",
            "style": "IPY_MODEL_6b849bafd89e4dfd8cb0375f63a8ea05",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "586b0293badc412e9b031918b90238c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1c715a482f64dea9d9535d293bcdf43",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9ef2855f5574d078f23391d9f36351a",
            "value": 0
          }
        },
        "61d7a7d3c0fd4d74b9c121194024854e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61d9fb8b3c3845358401afdb915a25b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aca07b2a90ff46bb86e208f7ba6418c4",
            "placeholder": "​",
            "style": "IPY_MODEL_0543e4c66952455391d1fbbe8ce3ab06",
            "value": " 500/500 [00:00&lt;00:00, 3563.59it/s]"
          }
        },
        "652c8a8cc9044bbfbd0250f8d4986bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80599b92522f45da9c25e98aebeffd7d",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f03602def896441798d02d56ad43266b",
            "value": 500
          }
        },
        "666fbf0acf674c6299369e1069147fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69101fa206c247f48df456eb1f3d0321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b436a053ba284c4eb18cc7b1be97add4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43e1613cbf814abb8be2c5c7dd6eaa6e",
            "value": 0
          }
        },
        "6b849bafd89e4dfd8cb0375f63a8ea05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d7719c6ff7b4b11b386966a95f04135": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61d7a7d3c0fd4d74b9c121194024854e",
            "placeholder": "​",
            "style": "IPY_MODEL_9af5e19b383e4d2d856450fe45595b02",
            "value": " 0/10 [00:00&lt;?, ?it/s]"
          }
        },
        "6db88d5fccd54570acfba5cd3fc489ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85bb0bdd1df14988b23592f2892a281a",
            "placeholder": "​",
            "style": "IPY_MODEL_47c156e672474744b9e758736ab33b3a",
            "value": "  0%"
          }
        },
        "7f20d3a4e1b34d0c96f36a42125aba2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09fccfab2c384d4ab14369a5d5091c4e",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbb1921f6b9343e3b43d55103a9e5c17",
            "value": 0
          }
        },
        "8057e16bdf9d4c64a10856edcb9d2837": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80599b92522f45da9c25e98aebeffd7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8287e3b2ecf6400b94d48b6b763aa0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85bb0bdd1df14988b23592f2892a281a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9af5e19b383e4d2d856450fe45595b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e15748d70f346dca29f5fc8b7693a58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aca07b2a90ff46bb86e208f7ba6418c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b15d8b41db684c5e8a467d2b4cb4fa85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1582dbf73cbb49ce98c9d69e3c5cae97",
              "IPY_MODEL_586b0293badc412e9b031918b90238c1",
              "IPY_MODEL_6d7719c6ff7b4b11b386966a95f04135"
            ],
            "layout": "IPY_MODEL_c5709476f9844483a5b92ca09b7ea30f"
          }
        },
        "b436a053ba284c4eb18cc7b1be97add4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bbb1921f6b9343e3b43d55103a9e5c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5709476f9844483a5b92ca09b7ea30f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c68c59833bc744d493abceee8527662b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca647d8fd81e49c8a16525ef7fc0ee0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e15748d70f346dca29f5fc8b7693a58",
            "placeholder": "​",
            "style": "IPY_MODEL_8057e16bdf9d4c64a10856edcb9d2837",
            "value": " 0/25 [00:00&lt;?, ?it/s]"
          }
        },
        "d170d01fda2641dfafffb7f667e15e67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d19b9c2edc154314bc5cff40a8c58349": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d47b553049dc4448996d083a05fad32e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_437ca6158fdf4165a42805c0c4cb4c23",
              "IPY_MODEL_69101fa206c247f48df456eb1f3d0321",
              "IPY_MODEL_4f4f801249b844eda135a284e62754c0"
            ],
            "layout": "IPY_MODEL_666fbf0acf674c6299369e1069147fdc"
          }
        },
        "ddbb91e33394474985ea4934d09984a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1c715a482f64dea9d9535d293bcdf43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9ef2855f5574d078f23391d9f36351a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea06ea8e2c4d4e75b4c8fad5cd9a6130": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f03602def896441798d02d56ad43266b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb1468fab3ec48ae972ee470f46602b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
